{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "542a5ee7",
   "metadata": {},
   "source": [
    "Introduction\n",
    "\n",
    "In this notebook, we perform text preprocessing on the Yelp Review Full dataset.\n",
    "The goal is to clean and normalize reviews to improve model performance and reduce noise.\n",
    "\n",
    "Objectives:\n",
    "\n",
    "Remove noisy and irrelevant text patterns\n",
    "\n",
    "Normalize text format\n",
    "\n",
    "Handle emojis and punctuation\n",
    "\n",
    "Prepare clean text for Transformer-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fbfaed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srinivasan\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Hugging Face dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Emoji handling\n",
    "import emoji\n",
    "\n",
    "# Progress bar (SAFE for VS Code)\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 300)\n",
    "print(\"All imports successful\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed84e4a8",
   "metadata": {},
   "source": [
    "Load Dataset\n",
    "\n",
    "We reload the Yelp Review Full dataset to apply preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4824c8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 650000\n",
      "Test size: 50000\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "\n",
    "train_ds = dataset[\"train\"]\n",
    "test_ds = dataset[\"test\"]\n",
    "\n",
    "print(\"Train size:\", len(train_ds))\n",
    "print(\"Test size:\", len(test_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84404ca9",
   "metadata": {},
   "source": [
    "Why Preprocessing Is Needed\n",
    "\n",
    "Real-world Yelp reviews contain:\n",
    "\n",
    "HTML tags\n",
    "\n",
    "URLs\n",
    "\n",
    "Emojis\n",
    "\n",
    "Excessive punctuation\n",
    "\n",
    "Irregular spacing\n",
    "\n",
    "Informal writing\n",
    "\n",
    "These can:\n",
    "\n",
    "Add noise\n",
    "\n",
    "Increase token length\n",
    "\n",
    "Confuse the model\n",
    "\n",
    "Define Text Cleaning Function\n",
    "\n",
    "We apply light but effective preprocessing, keeping semantic meaning intact.\n",
    "\n",
    "Cleaning Steps:\n",
    "\n",
    "1. Remove HTML tags\n",
    "\n",
    "2. Convert emojis to text\n",
    "\n",
    "3. Remove URLs\n",
    "\n",
    "4. Normalize punctuation\n",
    "\n",
    "5. Normalize whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179d2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \" \", text)\n",
    "    \n",
    "    # Convert emojis to text ( -> smiling_face)\n",
    "    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "    \n",
    "    # Remove excessive punctuation\n",
    "    text = re.sub(r\"[!?.]{2,}\", \".\", text)\n",
    "    \n",
    "    # Remove non-alphanumeric characters (keep basic punctuation)\n",
    "    text = re.sub(r\"[^a-z0-9\\s.,]\", \" \", text)\n",
    "    \n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ada7b1",
   "metadata": {},
   "source": [
    "Test Cleaning on Sample Reviews\n",
    "\n",
    "Before applying globally, we test preprocessing on sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42924a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TEXT:\n",
      "\n",
      "dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about hi\n",
      "\n",
      "CLEANED TEXT:\n",
      "\n",
      "dr. goldberg offers everything i look for in a general practitioner. he s nice and easy to talk to without being patronizing he s always on time in seeing his patients he s affiliated with a top notch hospital nyu which my parents have explained to me is very important in case something happens and you need surgery and you can get referrals to see specialists without having to see him first. really, what more do you need i m sitting here trying to think of any complaints i have about him, but i \n"
     ]
    }
   ],
   "source": [
    "sample_text = train_ds[0][\"text\"]\n",
    "\n",
    "print(\"ORIGINAL TEXT:\\n\")\n",
    "print(sample_text[:500])\n",
    "\n",
    "print(\"\\nCLEANED TEXT:\\n\")\n",
    "print(clean_text(sample_text)[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2698c56e",
   "metadata": {},
   "source": [
    "Apply Cleaning to Training Data\n",
    "\n",
    "We apply the cleaning function to all training reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7701d0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning training data: 100%|██████████| 650000/650000 [07:43<00:00, 1402.55 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds_clean = train_ds.map(\n",
    "    lambda x: {\"clean_text\": clean_text(x[\"text\"])},\n",
    "    desc=\"Cleaning training data\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27ac154",
   "metadata": {},
   "source": [
    "Apply Cleaning to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4db394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning test data: 100%|██████████| 50000/50000 [00:37<00:00, 1328.24 examples/s]\n"
     ]
    }
   ],
   "source": [
    "test_ds_clean = test_ds.map(\n",
    "    lambda x: {\"clean_text\": clean_text(x[\"text\"])},\n",
    "    desc=\"Cleaning test data\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e6fbda",
   "metadata": {},
   "source": [
    "Verify Cleaned Dataset Structure  & Review Cleaned Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78ef718e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label: 4\n",
      "Cleaned Text: dr. goldberg offers everything i look for in a general practitioner. he s nice and easy to talk to without being patronizing he s always on time in seeing his patients he s affiliated with a top notch hospital nyu which my parents have explained to me is very important in case something happens and you need surgery and you can get referrals to see specialists without having to see him first. reall\n",
      "\n",
      "Label: 1\n",
      "Cleaned Text: unfortunately, the frustration of being dr. goldberg s patient is a repeat of the experience i ve had with so many other doctors in nyc good doctor, terrible staff. it seems that his staff simply never answers the phone. it usually takes 2 hours of repeated calling to get an answer. who has time for that or wants to deal with it i have run into this problem with many other doctors and i just don t\n",
      "\n",
      "Label: 3\n",
      "Cleaned Text: been going to dr. goldberg for over 10 years. i think i was one of his 1st patients when he started at mhmg. he s been great over the years and is really all about the big picture. it is because of him, not my now former gyn dr. markoff, that i found out i have fibroids. he explores all options with you and is very patient and understanding. he doesn t judge and asks all the right questions. very \n"
     ]
    }
   ],
   "source": [
    "train_ds_clean.features\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"\\nLabel: {train_ds_clean[i]['label']}\")\n",
    "    print(\"Cleaned Text:\", train_ds_clean[i][\"clean_text\"][:400])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a5812e",
   "metadata": {},
   "source": [
    "Length Analysis After Cleaning\n",
    "\n",
    "Compare Length Before vs After Cleaning\n",
    "\n",
    "Handling Extremely Short Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c930a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of reviews shorter than 10 words: 1.59%\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame(train_ds_clean)\n",
    "\n",
    "train_df[\"clean_word_count\"] = train_df[\"clean_text\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "train_df[\"clean_word_count\"].describe()\n",
    "\n",
    "original_lengths = train_df[\"text\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"original\": original_lengths,\n",
    "    \"cleaned\": train_df[\"clean_word_count\"]\n",
    "})\n",
    "\n",
    "comparison_df.describe()\n",
    "\n",
    "short_reviews_pct = (train_df[\"clean_word_count\"] < 10).mean() * 100\n",
    "print(f\"Percentage reviews shorter than 10 words: {short_reviews_pct:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555adce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aa4e2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (2/2 shards): 100%|██████████| 650000/650000 [00:01<00:00, 439737.76 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 50000/50000 [00:00<00:00, 171505.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds_clean.save_to_disk(\"data/processed/train_clean\")\n",
    "test_ds_clean.save_to_disk(\"data/processed/test_clean\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
